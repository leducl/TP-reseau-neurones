---------------- EXERCICE 1 ----------------

Voir code

---------------- EXERCICE 2 ----------------

1. Pourquoi la fonction de Heaviside pose-t-elle problÃ¨me pour l'apprentissage par gradient ?
Parce quâ€™elle nâ€™est pas  diffÃ©rentiable : sa dÃ©rivÃ©e est nulle partout sauf au point de discontinuitÃ©.
Donc l'algorithme de rÃ©tropropagation  ne peut pas s'en servir pour ajuster les poids.

2. Quand utiliser sigmoid vs tanh ?
Sigmoid : utile pour des sorties entre 0 et 1 (ex : probabilitÃ©), mais souffre de saturation (vanishing gradient).
Tanh : centrÃ©e autour de 0 (sortie entre -1 et 1), ce qui rend lâ€™apprentissage plus stable que sigmoid dans beaucoup de cas.

3. Pourquoi ReLU est-elle si populaire dans les rÃ©seaux profonds ?
Simple Ã  calculer
Permet dâ€™Ã©viter partiellement le problÃ¨me du vanishing gradient
Active seulement une partie des neurones

4. Quel est l'avantage du Leaky ReLU ?
Il corrige un dÃ©faut du ReLU : quand lâ€™entrÃ©e est nÃ©gative, ReLU renvoie 0 â†’ les poids ne sont jamais mis Ã  jour.
Leaky ReLU permet un lÃ©ger gradient nÃ©gatif, donc continue Ã  apprendre mÃªme pour des valeurs nÃ©gatives.

---------------- EXERCICE 3 ----------------

Que se passe-t-il si ğœ‚ est trop grand ?
Si ğœ‚ est trop grand, lâ€™apprentissage devient instable et le perceptron peut ne jamais converger.

Et sâ€™il est trop petit ?
Si ğœ‚ est trop petit, lâ€™apprentissage est trÃ¨s lent et peut stagner.

Existe-t-il une valeur idÃ©ale de ğœ‚ ?
Il nâ€™existe pas de valeur idÃ©ale universelle de ğœ‚, cela dÃ©pend du problÃ¨me.

Peut-on faire varier ğœ‚ au cours du temps ?
Oui, on peut faire varier ğœ‚ au cours du temps.

Quelle stratÃ©gie pouvez-vous imaginer ?
Une bonne stratÃ©gie est de commencer avec un grand ğœ‚, puis de le rÃ©duire progressivement.

---------------- EXERCICE 4 ----------------

Voir code

---------------- EXERCICE 5 ----------------

Combien d'Ã©poques sont nÃ©cessaires pour converger ?
Pour AND, le perceptron converge en 5 Ã  15 Ã©poques en gÃ©nÃ©ral.
Pour OR, la convergence est encore plus rapide, souvent en 1 Ã  10 Ã©poques.
Le nombre exact dÃ©pend du taux dâ€™apprentissage et de lâ€™initialisation alÃ©atoire des poids.

Visualisez la droite de sÃ©paration trouvÃ©e.
Voir code

Le perceptron converge-t-il toujours vers la mÃªme solution ? (ie les mÃªmes poids)
Non, le perceptron ne converge pas toujours vers les mÃªmes poids.
Comme les poids sont initialisÃ©s alÃ©atoirement, plusieurs droites peuvent sÃ©parer les donnÃ©es correctement.
Cela nâ€™empÃªche pas le perceptron de trouver une bonne solution, tant que les donnÃ©es sont linÃ©airement sÃ©parables.

----------------EXERCICE 6 ----------------

Quelles sont vos constatations ?
Le perceptron ne parvient pas Ã  converger avec les donnÃ©es XOR.
Il tourne en boucle ou stagne sans jamais rÃ©ussir Ã  sÃ©parer correctement les classes.
La prÃ©cision reste autour de 50 %, mÃªme aprÃ¨s de nombreuses Ã©poques.

Quel lien peut-on faire avec la notion de sÃ©parabilitÃ© linÃ©aire Ã©voquÃ©e plus tÃ´t dans le cours ?
Le problÃ¨me XOR nâ€™est pas linÃ©airement sÃ©parables.
Aucune droite ne peut sÃ©parer les sorties -1 et 1 dans le plan.
Cela viole la condition fondamentale pour quâ€™un perceptron simple fonctionne correctement.

---------------- EXERCICE 7 ----------------

Lancez plusieurs fois votre programme, que constatez-vous sur la droite apprise ?
Quand on lance plusieurs fois le programme,
la droite apprise par le perceptron change pas ou du moins visuellement je ne vois aucunes differences

---------------- EXERCICE 8 ----------------

Quel comportement observez-vous lorsque n est trÃ¨s petit ?
quand n tres petit : apprentissage tres lent, erreurs baissent doucement

Que se passe-t-il lorsque n est trop grand ?
quand n trop grand : poids oscillent, pas de convergence

Existe-t-il un n optimal dans votre cas ?
oui, un n intermediaire (par ex 0.01) marche mieux ici

Comment la structure des donnÃ©es (dispersion, bruitâ€¦) peut-elle interagir avec n ?
plus de dispersion ou de bruit â†’ faut n plus petit pour pas diverger

---------------- EXERCICE 9 ----------------

CohÃ©rence des prÃ©dictions : Que se passe-t-il si plusieurs perceptrons prÃ©disent positivement pour le mÃªme exemple ?
on compare les scores bruts et on choisit la classe au score le plus Ã©levÃ©.

Gestion des ambiguÃ¯tÃ©s : Comment gÃ©rer le cas oÃ¹ aucun perceptron ne prÃ©dit positivement ?
comme on prend le max, on retourne quand mÃªme la classe moins nÃ©gative (celle dont le score est le plus grand).

Ã‰quilibrage : Comment l'approche "Un contre Tous" gÃ¨re-t-elle le dÃ©sÃ©quilibre naturel qu'elle crÃ©e ?
chaque perceptron voit une classe minoritaire vs toutes les autres, donc lâ€™apprentissage peut Ãªtre biaisÃ©
on peut compenser en ajustant learning_rate ou en pondÃ©rant les exemples

---------------- EXERCICE 10 ----------------

PAS DE QUESTION

---------------- EXERCICE 11 ----------------

Convergence
Le perceptron converge si les donnÃ©es sont linÃ©airement sÃ©parables et si le taux dâ€™apprentissage est suffisamment petit.
Sinon, il peut osciller sans trouver de solution parfaite.

Initialisation
Lâ€™initialisation nâ€™influence pas la solution finale pour un problÃ¨me linÃ©airement sÃ©parable,
mais peut affecter le nombre dâ€™itÃ©rations nÃ©cessaires Ã  la convergence.

Taux dâ€™apprentissage
On choisit Î· via une recherche sur grille ou en diminuant Î· progressivement
Lâ€™ensemble de validation permet dâ€™identifier le meilleur compromis entraÃ®nement / validation.

GÃ©nÃ©ralisation
On Ã©value la gÃ©nÃ©ralisation sur un jeu de test indÃ©pendant, jamais utilisÃ© pour lâ€™entraÃ®nement ou le rÃ©glage dâ€™hyperparamÃ¨tres.
On peut Ã©galement croiser avec la validation croisÃ©e pour estimer la variance.

XOR RevisitÃ©
Le problÃ¨me XOR nâ€™est pas linÃ©airement sÃ©parable. Solutions :
Ajouter une couche cachÃ©e
Transformer lâ€™espace pour rendre les donnÃ©es sÃ©parables.

DonnÃ©es bruitÃ©es
Le perceptron est sensible au bruit : il peut apprendre des exemples aberrants et ne plus converger proprement.
On peut limiter le nombre dâ€™itÃ©rations, ajouter un terme de rÃ©gularisation ou faire du nettoyage / filtrage du bruit.

Classes dÃ©sÃ©quilibrÃ©es
Si une classe est minoritaire, le perceptron aura tendance Ã  privilÃ©gier la classe majoritaire.
Solutions : pondÃ©rer les mises Ã  jour, sous-Ã©chantillonner la majoritÃ© ou sur-Ã©chantillonner la minoritÃ©.

Normalisation
Toujours normaliser les donnÃ©es avant lâ€™entraÃ®nement :
cela accÃ©lÃ¨re la convergence et assure que chaque caractÃ©ristique contribue de maniÃ¨re Ã©quitable aux mises Ã  jour.
